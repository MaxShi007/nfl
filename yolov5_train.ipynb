{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "from shutil import copyfile\n",
    "from sklearn.model_selection import KFold \n",
    "import cv2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_labels_file = \"nfl-health-and-safety-helmet-assignment/image_labels.csv\"\n",
    "image_labels = pd.read_csv(image_labels_file)\n",
    "# image_labels['image']\n",
    "# image_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7957/7957 [03:24<00:00, 38.98it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1990/1990 [00:37<00:00, 52.92it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7957/7957 [03:25<00:00, 38.76it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1990/1990 [00:37<00:00, 53.62it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7958/7958 [03:23<00:00, 39.06it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1989/1989 [00:36<00:00, 54.77it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7958/7958 [03:23<00:00, 39.03it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1989/1989 [00:35<00:00, 55.72it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7958/7958 [03:24<00:00, 38.84it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1989/1989 [00:34<00:00, 57.12it/s]\n"
     ]
    }
   ],
   "source": [
    "def get_yolo_format_bbox(img_w, img_h, box):\n",
    "\n",
    "    w = box.width.values  # width\n",
    "    h = box.height.values  # height\n",
    "    xc = box.left.values + np.round(w / 2)  # xmin + width/2\n",
    "    yc = box.top.values + np.round(h / 2) # ymin + height/2\n",
    "    # print(w)\n",
    "    # print(xc)\n",
    "\n",
    "    return pd.DataFrame({'x':xc / img_w, 'y':yc / img_h, 'w':w / img_w, 'h':h / img_h} ) # x_center y_center width height\n",
    "\n",
    "\n",
    "def fold_csv2yolo(csv_root,yolo_root,train_label,val_label):\n",
    "    TRAIN_IMAGES=f'{yolo_root}/images/train'\n",
    "    VAL_IMAGES=f'{yolo_root}/images/val'\n",
    "    TRAIN_LABELS=f'{yolo_root}/labels/train'\n",
    "    VAL_LABELS=f'{yolo_root}/labels/val'\n",
    "\n",
    "\n",
    "    if not os.path.exists(TRAIN_IMAGES): os.makedirs(TRAIN_IMAGES)\n",
    "    if not os.path.exists(VAL_IMAGES): os.makedirs(VAL_IMAGES)\n",
    "    if not os.path.exists(TRAIN_LABELS):os.makedirs(TRAIN_LABELS)\n",
    "    if not os.path.exists(VAL_LABELS): os.makedirs(VAL_LABELS)\n",
    "\n",
    "    train_image=train_label.image.drop_duplicates().values\n",
    "    val_image=val_label.image.drop_duplicates().values\n",
    "\n",
    "    for image in tqdm(train_image):\n",
    "        copyfile(f'{csv_root}/images/{image}',f'{TRAIN_IMAGES}/{image}')\n",
    "\n",
    "        label=train_label.loc[train_label['image']==image]\n",
    "        box=label[['left','top','width','height']]\n",
    "        # print(box)\n",
    "        img=cv2.imread(f'{csv_root}/images/{image}')\n",
    "        h,w,_=img.shape\n",
    "        box=get_yolo_format_bbox(w,h,box)\n",
    "        file=image.split('.')[0]\n",
    "        label_file_name=f'{TRAIN_LABELS}/{file}.txt'\n",
    "        with open(label_file_name,'w') as f:\n",
    "            for i,data in box.iterrows():\n",
    "                label=[str(i) for i in data.values]\n",
    "                label=' '.join(label)\n",
    "                label=str(0)+' '+label\n",
    "                f.write(label)\n",
    "                f.write('\\n')\n",
    "\n",
    "    for image in tqdm(val_image):\n",
    "        copyfile(f'{csv_root}/images/{image}',f'{VAL_IMAGES}/{image}')\n",
    "\n",
    "        label=val_label.loc[val_label['image']==image]\n",
    "        box=label[['left','top','width','height']]\n",
    "        # print(box)\n",
    "        img=cv2.imread(f'{csv_root}/images/{image}')\n",
    "        h,w,_=img.shape\n",
    "        box=get_yolo_format_bbox(w,h,box)\n",
    "        \n",
    "        file=image.split('.')[0]\n",
    "        label_file_name=f'{VAL_LABELS}/{file}.txt'\n",
    "        with open(label_file_name,'w') as f:\n",
    "            for i,data in box.iterrows():\n",
    "                label=[str(i) for i in data.values]\n",
    "                label=' '.join(label)\n",
    "                label=str(0)+' '+label\n",
    "                f.write(label)\n",
    "                f.write('\\n')\n",
    "\n",
    "    # print(train_image,len(train_image))\n",
    "\n",
    "\n",
    "n_splits=5\n",
    "kf = KFold(n_splits=n_splits,shuffle=False) \n",
    "image=image_labels['image'].drop_duplicates().reset_index(drop=True).values\n",
    "# print(image.shape)\n",
    "fold_num=0\n",
    "for train_image_idx,val_image_idx in kf.split(image):\n",
    "    # print(train_image_idx)\n",
    "    train_image,val_image=image[train_image_idx],image[val_image_idx]\n",
    "    # print(train_image,len(train_image))\n",
    "    train_image_label,val_image_label=image_labels.loc[image_labels.image.isin(train_image) ],image_labels.loc[image_labels.image.isin(val_image) ]\n",
    "    # print(train_image_label)\n",
    "    \n",
    "    yolo_root=f'yolov5/datasets/fold{fold_num}'\n",
    "    csv_root='nfl-health-and-safety-helmet-assignment'\n",
    "    if not os.path.exists(yolo_root):os.makedirs(yolo_root)\n",
    "    fold_csv2yolo(csv_root,yolo_root,train_image_label,val_image_label)\n",
    "    fold_num+=1\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/shigb/nfl/yolov5\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5x6.pt, cfg=, data=nfl_fold1.yaml, hyp=data/hyps/hyp.scratch.yaml, epochs=10, batch_size=10, imgsz=1280, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=NFL_YoloV5, name=yolov5x6_fold1, exist_ok=False, quad=False, linear_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
      "Command 'git fetch && git config --get remote.origin.url' timed out after 5 seconds\n",
      "YOLOv5 ðŸš€ v6.0-270-g0365379 torch 1.10.0+cu102 CUDA:0 (Tesla V100-SXM2-16GB, 16160MiB)\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.1, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
      "\u001b[34m\u001b[1mWeights & Biases: \u001b[0mrun 'pip install wandb' to automatically track and visualize YOLOv5 ðŸš€ runs (RECOMMENDED)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir NFL_YoloV5', view at http://localhost:6006/\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      8800  models.common.Conv                      [3, 80, 6, 2, 2]              \n",
      "  1                -1  1    115520  models.common.Conv                      [80, 160, 3, 2]               \n",
      "  2                -1  4    309120  models.common.C3                        [160, 160, 4]                 \n",
      "  3                -1  1    461440  models.common.Conv                      [160, 320, 3, 2]              \n",
      "  4                -1  8   2259200  models.common.C3                        [320, 320, 8]                 \n",
      "  5                -1  1   1844480  models.common.Conv                      [320, 640, 3, 2]              \n",
      "  6                -1 12  13125120  models.common.C3                        [640, 640, 12]                \n",
      "  7                -1  1   5531520  models.common.Conv                      [640, 960, 3, 2]              \n",
      "  8                -1  4  11070720  models.common.C3                        [960, 960, 4]                 \n",
      "  9                -1  1  11061760  models.common.Conv                      [960, 1280, 3, 2]             \n",
      " 10                -1  4  19676160  models.common.C3                        [1280, 1280, 4]               \n",
      " 11                -1  1   4099840  models.common.SPPF                      [1280, 1280, 5]               \n",
      " 12                -1  1   1230720  models.common.Conv                      [1280, 960, 1, 1]             \n",
      " 13                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 14           [-1, 8]  1         0  models.common.Concat                    [1]                           \n",
      " 15                -1  4  11992320  models.common.C3                        [1920, 960, 4, False]         \n",
      " 16                -1  1    615680  models.common.Conv                      [960, 640, 1, 1]              \n",
      " 17                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 18           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 19                -1  4   5332480  models.common.C3                        [1280, 640, 4, False]         \n",
      " 20                -1  1    205440  models.common.Conv                      [640, 320, 1, 1]              \n",
      " 21                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 22           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  4   1335040  models.common.C3                        [640, 320, 4, False]          \n",
      " 24                -1  1    922240  models.common.Conv                      [320, 320, 3, 2]              \n",
      " 25          [-1, 20]  1         0  models.common.Concat                    [1]                           \n",
      " 26                -1  4   4922880  models.common.C3                        [640, 640, 4, False]          \n",
      " 27                -1  1   3687680  models.common.Conv                      [640, 640, 3, 2]              \n",
      " 28          [-1, 16]  1         0  models.common.Concat                    [1]                           \n",
      " 29                -1  4  11377920  models.common.C3                        [1280, 960, 4, False]         \n",
      " 30                -1  1   8296320  models.common.Conv                      [960, 960, 3, 2]              \n",
      " 31          [-1, 12]  1         0  models.common.Concat                    [1]                           \n",
      " 32                -1  4  20495360  models.common.C3                        [1920, 1280, 4, False]        \n",
      " 33  [23, 26, 29, 32]  1     57672  models.yolo.Detect                      [1, [[19, 27, 44, 40, 38, 94], [96, 68, 86, 152, 180, 137], [140, 301, 303, 264, 238, 542], [436, 615, 739, 380, 925, 792]], [320, 640, 960, 1280]]\n",
      "Model Summary: 733 layers, 140035432 parameters, 140035432 gradients, 208.3 GFLOPs\n",
      "\n",
      "Transferred 955/963 items from yolov5x6.pt\n",
      "Scaled weight_decay = 0.00046875\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD with parameter groups 159 weight (no decay), 163 weight, 163 bias\n",
      "WARNING: DP not recommended, use torch.distributed.run for best DDP Multi-GPU results.\n",
      "See Multi-GPU Tutorial at https://github.com/ultralytics/yolov5/issues/475 to get started.\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/home/shigb/nfl/yolov5/datasets/fold1/labels/train.cache' image\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '/home/shigb/nfl/yolov5/datasets/fold1/labels/val.cache' images an\u001b[0m\n",
      "Plotting labels to NFL_YoloV5/yolov5x6_fold1/labels.jpg... \n",
      "\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m2.26 anchors/target, 0.972 Best Possible Recall (BPR). Anchors are a poor fit to dataset âš ï¸, attempting to improve...\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mRunning kmeans for 12 anchors on 156129 points...\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.8892: 100%|â–ˆ| 1\u001b[0m\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mthr=0.25: 1.0000 best possible recall, 11.21 anchors past thr\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mn=12, img_size=1280, metric_all=0.558/0.889-mean/best, past_thr=0.582-mean: 8,8, 10,10, 12,13, 15,14, 14,17, 18,19, 23,20, 23,25, 29,26, 26,32, 34,36, 45,45\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mReversing anchor order\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mNew anchors saved to model. Update model *.yaml to use these anchors in the future.\n",
      "Image sizes 1280 train, 1280 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mNFL_YoloV5/yolov5x6_fold1\u001b[0m\n",
      "Starting training for 10 epochs...\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       0/9     12.8G    0.1064   0.09283         0       151      1280: 100%|â–ˆâ–ˆâ–ˆ\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       1990      37607       0.93      0.805      0.877      0.419\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       1/9     11.7G   0.07973   0.09369         0       203      1280: 100%|â–ˆâ–ˆâ–ˆ\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       1990      37607      0.934      0.818      0.892      0.423\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       2/9     11.7G   0.08359    0.1001         0       185      1280: 100%|â–ˆâ–ˆâ–ˆ\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       1990      37607       0.92      0.813      0.875      0.379\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       3/9     11.7G   0.07242   0.09067         0       240      1280: 100%|â–ˆâ–ˆâ–ˆ\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       1990      37607       0.94      0.866      0.924      0.518\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       4/9     11.7G   0.06683   0.08765         0       190      1280: 100%|â–ˆâ–ˆâ–ˆ\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       1990      37607      0.951      0.875      0.931      0.537\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       5/9     11.7G   0.06236   0.08497         0       245      1280: 100%|â–ˆâ–ˆâ–ˆ\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       1990      37607      0.945      0.888      0.936      0.558\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       6/9     11.7G   0.05982   0.08357         0       166      1280: 100%|â–ˆâ–ˆâ–ˆ\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       1990      37607       0.95      0.891      0.939      0.563\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       7/9     11.7G   0.05762   0.08169         0       216      1280: 100%|â–ˆâ–ˆâ–ˆ\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       1990      37607      0.949      0.895       0.94      0.568\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       8/9     11.7G   0.05645   0.08095         0       199      1280: 100%|â–ˆâ–ˆâ–ˆ\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       1990      37607      0.949        0.9      0.943      0.576\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       9/9     11.7G   0.05616   0.08198         0       160      1280: 100%|â–ˆâ–ˆâ–ˆ\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       1990      37607      0.949      0.903      0.945      0.577\n",
      "\n",
      "10 epochs completed in 1.101 hours.\n",
      "Optimizer stripped from NFL_YoloV5/yolov5x6_fold1/weights/last.pt, 281.2MB\n",
      "Optimizer stripped from NFL_YoloV5/yolov5x6_fold1/weights/best.pt, 281.2MB\n",
      "\n",
      "Validating NFL_YoloV5/yolov5x6_fold1/weights/best.pt...\n",
      "Fusing layers... \n",
      "Model Summary: 574 layers, 139970872 parameters, 0 gradients, 208.1 GFLOPs\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       1990      37607      0.949      0.903      0.945      0.577\n",
      "Results saved to \u001b[1mNFL_YoloV5/yolov5x6_fold1\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%cd /home/shigb/nfl/yolov5\n",
    "# map 0.95 r 0.8\n",
    "!python train.py --img 1280 --batch 10  --project NFL_YoloV5 --epochs 10 --data nfl_fold1.yaml --name yolov5x6_fold1 --weights yolov5x6.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5x6.pt, cfg=, data=nfl_fold2.yaml, hyp=data/hyps/hyp.scratch.yaml, epochs=10, batch_size=10, imgsz=1280, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=NFL_YoloV5, name=yolov5x6_fold2, exist_ok=False, quad=False, linear_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
      "\u001b[34m\u001b[1mgithub: \u001b[0mâš ï¸ YOLOv5 is out of date by 6 commits. Use `git pull` or `git clone git@github.com:ultralytics/yolov5` to update.\n",
      "YOLOv5 ðŸš€ v6.0-270-g0365379 torch 1.10.0+cu102 CUDA:0 (Tesla V100-SXM2-16GB, 16160MiB)\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.1, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
      "\u001b[34m\u001b[1mWeights & Biases: \u001b[0mrun 'pip install wandb' to automatically track and visualize YOLOv5 ðŸš€ runs (RECOMMENDED)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir NFL_YoloV5', view at http://localhost:6006/\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      8800  models.common.Conv                      [3, 80, 6, 2, 2]              \n",
      "  1                -1  1    115520  models.common.Conv                      [80, 160, 3, 2]               \n",
      "  2                -1  4    309120  models.common.C3                        [160, 160, 4]                 \n",
      "  3                -1  1    461440  models.common.Conv                      [160, 320, 3, 2]              \n",
      "  4                -1  8   2259200  models.common.C3                        [320, 320, 8]                 \n",
      "  5                -1  1   1844480  models.common.Conv                      [320, 640, 3, 2]              \n",
      "  6                -1 12  13125120  models.common.C3                        [640, 640, 12]                \n",
      "  7                -1  1   5531520  models.common.Conv                      [640, 960, 3, 2]              \n",
      "  8                -1  4  11070720  models.common.C3                        [960, 960, 4]                 \n",
      "  9                -1  1  11061760  models.common.Conv                      [960, 1280, 3, 2]             \n",
      " 10                -1  4  19676160  models.common.C3                        [1280, 1280, 4]               \n",
      " 11                -1  1   4099840  models.common.SPPF                      [1280, 1280, 5]               \n",
      " 12                -1  1   1230720  models.common.Conv                      [1280, 960, 1, 1]             \n",
      " 13                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 14           [-1, 8]  1         0  models.common.Concat                    [1]                           \n",
      " 15                -1  4  11992320  models.common.C3                        [1920, 960, 4, False]         \n",
      " 16                -1  1    615680  models.common.Conv                      [960, 640, 1, 1]              \n",
      " 17                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 18           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 19                -1  4   5332480  models.common.C3                        [1280, 640, 4, False]         \n",
      " 20                -1  1    205440  models.common.Conv                      [640, 320, 1, 1]              \n",
      " 21                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 22           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  4   1335040  models.common.C3                        [640, 320, 4, False]          \n",
      " 24                -1  1    922240  models.common.Conv                      [320, 320, 3, 2]              \n",
      " 25          [-1, 20]  1         0  models.common.Concat                    [1]                           \n",
      " 26                -1  4   4922880  models.common.C3                        [640, 640, 4, False]          \n",
      " 27                -1  1   3687680  models.common.Conv                      [640, 640, 3, 2]              \n",
      " 28          [-1, 16]  1         0  models.common.Concat                    [1]                           \n",
      " 29                -1  4  11377920  models.common.C3                        [1280, 960, 4, False]         \n",
      " 30                -1  1   8296320  models.common.Conv                      [960, 960, 3, 2]              \n",
      " 31          [-1, 12]  1         0  models.common.Concat                    [1]                           \n",
      " 32                -1  4  20495360  models.common.C3                        [1920, 1280, 4, False]        \n",
      " 33  [23, 26, 29, 32]  1     57672  models.yolo.Detect                      [1, [[19, 27, 44, 40, 38, 94], [96, 68, 86, 152, 180, 137], [140, 301, 303, 264, 238, 542], [436, 615, 739, 380, 925, 792]], [320, 640, 960, 1280]]\n",
      "Model Summary: 733 layers, 140035432 parameters, 140035432 gradients, 208.3 GFLOPs\n",
      "\n",
      "Transferred 955/963 items from yolov5x6.pt\n",
      "Scaled weight_decay = 0.00046875\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD with parameter groups 159 weight (no decay), 163 weight, 163 bias\n",
      "WARNING: DP not recommended, use torch.distributed.run for best DDP Multi-GPU results.\n",
      "See Multi-GPU Tutorial at https://github.com/ultralytics/yolov5/issues/475 to get started.\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/home/shigb/nfl/yolov5/datasets/fold2/labels/train' images and \u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /home/shigb/nfl/yolov5/datasets/fold2/labels/train.cache\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '/home/shigb/nfl/yolov5/datasets/fold2/labels/val' images and labe\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /home/shigb/nfl/yolov5/datasets/fold2/labels/val.cache\n",
      "Plotting labels to NFL_YoloV5/yolov5x6_fold2/labels.jpg... \n",
      "\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m2.28 anchors/target, 0.970 Best Possible Recall (BPR). Anchors are a poor fit to dataset âš ï¸, attempting to improve...\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mRunning kmeans for 12 anchors on 154935 points...\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.8864: 100%|â–ˆ| 1\u001b[0m\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mthr=0.25: 1.0000 best possible recall, 11.17 anchors past thr\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mn=12, img_size=1280, metric_all=0.555/0.886-mean/best, past_thr=0.581-mean: 8,8, 10,11, 13,13, 16,15, 15,18, 19,19, 24,22, 22,27, 28,27, 24,35, 33,36, 48,47\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mReversing anchor order\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mNew anchors saved to model. Update model *.yaml to use these anchors in the future.\n",
      "Image sizes 1280 train, 1280 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mNFL_YoloV5/yolov5x6_fold2\u001b[0m\n",
      "Starting training for 10 epochs...\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       0/9     12.2G    0.1052   0.09287         0       280      1280: 100%|â–ˆâ–ˆâ–ˆ\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       1989      38801      0.913      0.765      0.853      0.351\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       1/9     11.7G   0.07865   0.09262         0       251      1280: 100%|â–ˆâ–ˆâ–ˆ\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       1989      38801      0.896      0.773      0.879       0.43\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       2/9     11.7G   0.07454    0.0907         0       296      1280: 100%|â–ˆâ–ˆâ–ˆ\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       1989      38801      0.908      0.844      0.911      0.517\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       3/9     11.7G   0.06599   0.08577         0       313      1280: 100%|â–ˆâ–ˆâ–ˆ\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       1989      38801      0.943      0.872      0.929      0.544\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       4/9     11.7G   0.06244   0.08456         0       245      1280: 100%|â–ˆâ–ˆâ–ˆ\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       1989      38801      0.949      0.883      0.936       0.56\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       5/9     11.7G   0.05886     0.082         0       212      1280: 100%|â–ˆâ–ˆâ–ˆ\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       1989      38801      0.948       0.89      0.942      0.573\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       6/9     11.7G   0.05643   0.08084         0       242      1280: 100%|â–ˆâ–ˆâ–ˆ\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       1989      38801      0.944      0.897      0.944      0.577\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       7/9     11.7G   0.05491   0.07972         0       311      1280: 100%|â–ˆâ–ˆâ–ˆ\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       1989      38801      0.955      0.892      0.946      0.583\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       8/9     11.7G   0.05431   0.07959         0       255      1280: 100%|â–ˆâ–ˆâ–ˆ\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       1989      38801       0.95      0.899      0.948      0.585\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       9/9     11.7G   0.05352   0.07845         0       251      1280: 100%|â–ˆâ–ˆâ–ˆ\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       1989      38801      0.955      0.896      0.948       0.59\n",
      "\n",
      "10 epochs completed in 1.116 hours.\n",
      "Optimizer stripped from NFL_YoloV5/yolov5x6_fold2/weights/last.pt, 281.2MB\n",
      "Optimizer stripped from NFL_YoloV5/yolov5x6_fold2/weights/best.pt, 281.2MB\n",
      "\n",
      "Validating NFL_YoloV5/yolov5x6_fold2/weights/best.pt...\n",
      "Fusing layers... \n",
      "Model Summary: 574 layers, 139970872 parameters, 0 gradients, 208.1 GFLOPs\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       1989      38801      0.956      0.895      0.948       0.59\n",
      "Results saved to \u001b[1mNFL_YoloV5/yolov5x6_fold2\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python train.py --img 1280 --batch 10  --project NFL_YoloV5 --epochs 10 --data nfl_fold2.yaml --name yolov5x6_fold2 --weights yolov5x6.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5x6.pt, cfg=, data=nfl_fold3.yaml, hyp=data/hyps/hyp.scratch.yaml, epochs=10, batch_size=10, imgsz=1280, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=NFL_YoloV5, name=yolov5x6_fold3, exist_ok=False, quad=False, linear_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
      "\u001b[34m\u001b[1mgithub: \u001b[0mâš ï¸ YOLOv5 is out of date by 6 commits. Use `git pull` or `git clone git@github.com:ultralytics/yolov5` to update.\n",
      "YOLOv5 ðŸš€ v6.0-270-g0365379 torch 1.10.0+cu102 CUDA:0 (Tesla V100-SXM2-16GB, 16160MiB)\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.1, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
      "\u001b[34m\u001b[1mWeights & Biases: \u001b[0mrun 'pip install wandb' to automatically track and visualize YOLOv5 ðŸš€ runs (RECOMMENDED)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir NFL_YoloV5', view at http://localhost:6006/\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      8800  models.common.Conv                      [3, 80, 6, 2, 2]              \n",
      "  1                -1  1    115520  models.common.Conv                      [80, 160, 3, 2]               \n",
      "  2                -1  4    309120  models.common.C3                        [160, 160, 4]                 \n",
      "  3                -1  1    461440  models.common.Conv                      [160, 320, 3, 2]              \n",
      "  4                -1  8   2259200  models.common.C3                        [320, 320, 8]                 \n",
      "  5                -1  1   1844480  models.common.Conv                      [320, 640, 3, 2]              \n",
      "  6                -1 12  13125120  models.common.C3                        [640, 640, 12]                \n",
      "  7                -1  1   5531520  models.common.Conv                      [640, 960, 3, 2]              \n",
      "  8                -1  4  11070720  models.common.C3                        [960, 960, 4]                 \n",
      "  9                -1  1  11061760  models.common.Conv                      [960, 1280, 3, 2]             \n",
      " 10                -1  4  19676160  models.common.C3                        [1280, 1280, 4]               \n",
      " 11                -1  1   4099840  models.common.SPPF                      [1280, 1280, 5]               \n",
      " 12                -1  1   1230720  models.common.Conv                      [1280, 960, 1, 1]             \n",
      " 13                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 14           [-1, 8]  1         0  models.common.Concat                    [1]                           \n",
      " 15                -1  4  11992320  models.common.C3                        [1920, 960, 4, False]         \n",
      " 16                -1  1    615680  models.common.Conv                      [960, 640, 1, 1]              \n",
      " 17                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 18           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 19                -1  4   5332480  models.common.C3                        [1280, 640, 4, False]         \n",
      " 20                -1  1    205440  models.common.Conv                      [640, 320, 1, 1]              \n",
      " 21                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 22           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  4   1335040  models.common.C3                        [640, 320, 4, False]          \n",
      " 24                -1  1    922240  models.common.Conv                      [320, 320, 3, 2]              \n",
      " 25          [-1, 20]  1         0  models.common.Concat                    [1]                           \n",
      " 26                -1  4   4922880  models.common.C3                        [640, 640, 4, False]          \n",
      " 27                -1  1   3687680  models.common.Conv                      [640, 640, 3, 2]              \n",
      " 28          [-1, 16]  1         0  models.common.Concat                    [1]                           \n",
      " 29                -1  4  11377920  models.common.C3                        [1280, 960, 4, False]         \n",
      " 30                -1  1   8296320  models.common.Conv                      [960, 960, 3, 2]              \n",
      " 31          [-1, 12]  1         0  models.common.Concat                    [1]                           \n",
      " 32                -1  4  20495360  models.common.C3                        [1920, 1280, 4, False]        \n",
      " 33  [23, 26, 29, 32]  1     57672  models.yolo.Detect                      [1, [[19, 27, 44, 40, 38, 94], [96, 68, 86, 152, 180, 137], [140, 301, 303, 264, 238, 542], [436, 615, 739, 380, 925, 792]], [320, 640, 960, 1280]]\n",
      "Model Summary: 733 layers, 140035432 parameters, 140035432 gradients, 208.3 GFLOPs\n",
      "\n",
      "Transferred 955/963 items from yolov5x6.pt\n",
      "Scaled weight_decay = 0.00046875\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD with parameter groups 159 weight (no decay), 163 weight, 163 bias\n",
      "WARNING: DP not recommended, use torch.distributed.run for best DDP Multi-GPU results.\n",
      "See Multi-GPU Tutorial at https://github.com/ultralytics/yolov5/issues/475 to get started.\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/home/shigb/nfl/yolov5/datasets/fold3/labels/train' images and \u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /home/shigb/nfl/yolov5/datasets/fold3/labels/train.cache\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '/home/shigb/nfl/yolov5/datasets/fold3/labels/val' images and labe\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /home/shigb/nfl/yolov5/datasets/fold3/labels/val.cache\n",
      "Plotting labels to NFL_YoloV5/yolov5x6_fold3/labels.jpg... \n",
      "\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m2.30 anchors/target, 0.971 Best Possible Recall (BPR). Anchors are a poor fit to dataset âš ï¸, attempting to improve...\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mRunning kmeans for 12 anchors on 153798 points...\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.8873: 100%|â–ˆ| 1\u001b[0m\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mthr=0.25: 1.0000 best possible recall, 11.09 anchors past thr\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mn=12, img_size=1280, metric_all=0.551/0.887-mean/best, past_thr=0.579-mean: 7,7, 9,10, 11,12, 14,14, 16,18, 20,16, 20,22, 25,23, 24,32, 29,28, 33,36, 45,47\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mReversing anchor order\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mNew anchors saved to model. Update model *.yaml to use these anchors in the future.\n",
      "Image sizes 1280 train, 1280 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mNFL_YoloV5/yolov5x6_fold3\u001b[0m\n",
      "Starting training for 10 epochs...\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       0/9     12.2G     0.106   0.09285         0       228      1280: 100%|â–ˆâ–ˆâ–ˆ\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       1989      39938      0.898      0.743      0.832      0.344\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       1/9     11.7G   0.07915   0.09279         0       214      1280: 100%|â–ˆâ–ˆâ–ˆ\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       1989      39938       0.93      0.825      0.894      0.448\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       2/9     11.7G   0.08008       0.1         0       273      1280: 100%|â–ˆâ–ˆâ–ˆ\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       1989      39938      0.897       0.78      0.843       0.35\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       3/9     11.7G   0.07041    0.0883         0       228      1280: 100%|â–ˆâ–ˆâ–ˆ\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       1989      39938      0.926      0.847      0.909        0.5\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       4/9     11.7G   0.06492   0.08602         0       242      1280: 100%|â–ˆâ–ˆâ–ˆ\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       1989      39938      0.932      0.859      0.917      0.528\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       5/9     11.7G   0.06096   0.08324         0       211      1280: 100%|â–ˆâ–ˆâ–ˆ\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       1989      39938       0.94      0.866      0.925      0.538\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       6/9     11.7G   0.05856   0.08211         0       257      1280: 100%|â–ˆâ–ˆâ–ˆ\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       1989      39938      0.937      0.874      0.928      0.549\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       7/9     11.7G   0.05661   0.08078         0       334      1280: 100%|â–ˆâ–ˆâ–ˆ\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       1989      39938      0.939      0.877       0.93      0.554\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       8/9     11.7G   0.05548    0.0796         0       323      1280: 100%|â–ˆâ–ˆâ–ˆ\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       1989      39938      0.937      0.885      0.933      0.556\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       9/9     11.7G   0.05497    0.0798         0       217      1280: 100%|â–ˆâ–ˆâ–ˆ\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       1989      39938      0.938      0.888      0.934       0.56\n",
      "\n",
      "10 epochs completed in 1.103 hours.\n",
      "Optimizer stripped from NFL_YoloV5/yolov5x6_fold3/weights/last.pt, 281.2MB\n",
      "Optimizer stripped from NFL_YoloV5/yolov5x6_fold3/weights/best.pt, 281.2MB\n",
      "\n",
      "Validating NFL_YoloV5/yolov5x6_fold3/weights/best.pt...\n",
      "Fusing layers... \n",
      "Model Summary: 574 layers, 139970872 parameters, 0 gradients, 208.1 GFLOPs\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       1989      39938      0.938      0.888      0.934      0.559\n",
      "Results saved to \u001b[1mNFL_YoloV5/yolov5x6_fold3\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python train.py --img 1280 --batch 10  --project NFL_YoloV5 --epochs 10 --data nfl_fold3.yaml --name yolov5x6_fold3 --weights yolov5x6.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5x6.pt, cfg=, data=nfl_fold4.yaml, hyp=data/hyps/hyp.scratch.yaml, epochs=10, batch_size=10, imgsz=1280, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=NFL_YoloV5, name=yolov5x6_fold4, exist_ok=False, quad=False, linear_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
      "\u001b[34m\u001b[1mgithub: \u001b[0mâš ï¸ YOLOv5 is out of date by 6 commits. Use `git pull` or `git clone git@github.com:ultralytics/yolov5` to update.\n",
      "YOLOv5 ðŸš€ v6.0-270-g0365379 torch 1.10.0+cu102 CUDA:0 (Tesla V100-SXM2-16GB, 16160MiB)\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.1, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
      "\u001b[34m\u001b[1mWeights & Biases: \u001b[0mrun 'pip install wandb' to automatically track and visualize YOLOv5 ðŸš€ runs (RECOMMENDED)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir NFL_YoloV5', view at http://localhost:6006/\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      8800  models.common.Conv                      [3, 80, 6, 2, 2]              \n",
      "  1                -1  1    115520  models.common.Conv                      [80, 160, 3, 2]               \n",
      "  2                -1  4    309120  models.common.C3                        [160, 160, 4]                 \n",
      "  3                -1  1    461440  models.common.Conv                      [160, 320, 3, 2]              \n",
      "  4                -1  8   2259200  models.common.C3                        [320, 320, 8]                 \n",
      "  5                -1  1   1844480  models.common.Conv                      [320, 640, 3, 2]              \n",
      "  6                -1 12  13125120  models.common.C3                        [640, 640, 12]                \n",
      "  7                -1  1   5531520  models.common.Conv                      [640, 960, 3, 2]              \n",
      "  8                -1  4  11070720  models.common.C3                        [960, 960, 4]                 \n",
      "  9                -1  1  11061760  models.common.Conv                      [960, 1280, 3, 2]             \n",
      " 10                -1  4  19676160  models.common.C3                        [1280, 1280, 4]               \n",
      " 11                -1  1   4099840  models.common.SPPF                      [1280, 1280, 5]               \n",
      " 12                -1  1   1230720  models.common.Conv                      [1280, 960, 1, 1]             \n",
      " 13                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 14           [-1, 8]  1         0  models.common.Concat                    [1]                           \n",
      " 15                -1  4  11992320  models.common.C3                        [1920, 960, 4, False]         \n",
      " 16                -1  1    615680  models.common.Conv                      [960, 640, 1, 1]              \n",
      " 17                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 18           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 19                -1  4   5332480  models.common.C3                        [1280, 640, 4, False]         \n",
      " 20                -1  1    205440  models.common.Conv                      [640, 320, 1, 1]              \n",
      " 21                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 22           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  4   1335040  models.common.C3                        [640, 320, 4, False]          \n",
      " 24                -1  1    922240  models.common.Conv                      [320, 320, 3, 2]              \n",
      " 25          [-1, 20]  1         0  models.common.Concat                    [1]                           \n",
      " 26                -1  4   4922880  models.common.C3                        [640, 640, 4, False]          \n",
      " 27                -1  1   3687680  models.common.Conv                      [640, 640, 3, 2]              \n",
      " 28          [-1, 16]  1         0  models.common.Concat                    [1]                           \n",
      " 29                -1  4  11377920  models.common.C3                        [1280, 960, 4, False]         \n",
      " 30                -1  1   8296320  models.common.Conv                      [960, 960, 3, 2]              \n",
      " 31          [-1, 12]  1         0  models.common.Concat                    [1]                           \n",
      " 32                -1  4  20495360  models.common.C3                        [1920, 1280, 4, False]        \n",
      " 33  [23, 26, 29, 32]  1     57672  models.yolo.Detect                      [1, [[19, 27, 44, 40, 38, 94], [96, 68, 86, 152, 180, 137], [140, 301, 303, 264, 238, 542], [436, 615, 739, 380, 925, 792]], [320, 640, 960, 1280]]\n",
      "Model Summary: 733 layers, 140035432 parameters, 140035432 gradients, 208.3 GFLOPs\n",
      "\n",
      "Transferred 955/963 items from yolov5x6.pt\n",
      "Scaled weight_decay = 0.00046875\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD with parameter groups 159 weight (no decay), 163 weight, 163 bias\n",
      "WARNING: DP not recommended, use torch.distributed.run for best DDP Multi-GPU results.\n",
      "See Multi-GPU Tutorial at https://github.com/ultralytics/yolov5/issues/475 to get started.\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/home/shigb/nfl/yolov5/datasets/fold4/labels/train' images and \u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /home/shigb/nfl/yolov5/datasets/fold4/labels/train.cache\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '/home/shigb/nfl/yolov5/datasets/fold4/labels/val' images and labe\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /home/shigb/nfl/yolov5/datasets/fold4/labels/val.cache\n",
      "Plotting labels to NFL_YoloV5/yolov5x6_fold4/labels.jpg... \n",
      "\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m2.29 anchors/target, 0.970 Best Possible Recall (BPR). Anchors are a poor fit to dataset âš ï¸, attempting to improve...\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mRunning kmeans for 12 anchors on 154371 points...\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.8843: 100%|â–ˆ| 1\u001b[0m\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mthr=0.25: 1.0000 best possible recall, 11.14 anchors past thr\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mn=12, img_size=1280, metric_all=0.553/0.884-mean/best, past_thr=0.580-mean: 8,8, 10,11, 13,14, 15,17, 21,17, 18,20, 24,22, 22,28, 28,28, 26,34, 34,37, 47,48\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mReversing anchor order\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mNew anchors saved to model. Update model *.yaml to use these anchors in the future.\n",
      "Image sizes 1280 train, 1280 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mNFL_YoloV5/yolov5x6_fold4\u001b[0m\n",
      "Starting training for 10 epochs...\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       0/9     12.2G    0.1039   0.09314         0       234      1280: 100%|â–ˆâ–ˆâ–ˆ\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       1989      39365      0.828      0.674       0.79      0.334\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       1/9     11.7G   0.07682   0.09173         0       272      1280: 100%|â–ˆâ–ˆâ–ˆ\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       1989      39365      0.842      0.713      0.835      0.404\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       2/9     11.7G   0.07327   0.08985         0       244      1280: 100%|â–ˆâ–ˆâ–ˆ\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       1989      39365      0.933      0.834      0.908      0.461\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       3/9     11.7G   0.06489   0.08543         0       269      1280: 100%|â–ˆâ–ˆâ–ˆ\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       1989      39365      0.934       0.86      0.921      0.512\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       4/9     11.7G   0.06085   0.08322         0       240      1280: 100%|â–ˆâ–ˆâ–ˆ\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       1989      39365      0.938      0.873      0.927      0.543\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       5/9     11.7G   0.05764    0.0816         0       250      1280: 100%|â–ˆâ–ˆâ–ˆ\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       1989      39365      0.933      0.874      0.928      0.537\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       6/9     11.7G   0.05512   0.08068         0       220      1280: 100%|â–ˆâ–ˆâ–ˆ\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       1989      39365       0.94      0.881      0.935      0.551\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       7/9     11.7G   0.05335   0.07897         0       348      1280: 100%|â–ˆâ–ˆâ–ˆ\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       1989      39365      0.943      0.886      0.938      0.555\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       8/9     11.7G   0.05241   0.07778         0       311      1280: 100%|â–ˆâ–ˆâ–ˆ\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       1989      39365      0.941      0.889      0.939      0.558\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       9/9     11.7G   0.05225   0.07892         0       232      1280: 100%|â–ˆâ–ˆâ–ˆ\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       1989      39365      0.943      0.888       0.94      0.559\n",
      "\n",
      "10 epochs completed in 1.103 hours.\n",
      "Optimizer stripped from NFL_YoloV5/yolov5x6_fold4/weights/last.pt, 281.2MB\n",
      "Optimizer stripped from NFL_YoloV5/yolov5x6_fold4/weights/best.pt, 281.2MB\n",
      "\n",
      "Validating NFL_YoloV5/yolov5x6_fold4/weights/best.pt...\n",
      "Fusing layers... \n",
      "Model Summary: 574 layers, 139970872 parameters, 0 gradients, 208.1 GFLOPs\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       1989      39365      0.944      0.888       0.94      0.559\n",
      "Results saved to \u001b[1mNFL_YoloV5/yolov5x6_fold4\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python train.py --img 1280 --batch 10  --project NFL_YoloV5 --epochs 10 --data nfl_fold4.yaml --name yolov5x6_fold4 --weights yolov5x6.pt"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "04e84f078c44cadffa401683b029ac5ffd47914a386017ea086bef06d0743bf2"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('yolov5')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
